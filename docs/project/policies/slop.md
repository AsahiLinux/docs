---
title: Generative AI Policy
---

It is the opinion of the Board that Large Language Models (LLMs), herein referred
to as Slop Generators, are unsuitable for use as software engineering tools,
particularly in the Free and Open Source Software movement.

The use of Slop Generators in _any_ contribution to the Asahi Linux project is
expressly forbidden. Their use in any material capacity where code, documentation,
engineering decisions, etc. are largely created with the "help" of a Slop Generators
will be met with a single warning. Subsequent disregard for this policy will be
met with an immediate and permanent ban from the Asahi Linux project and all
associated spaces.

## Illegal output
All of the popular Slop Generators are trained on an incomprehensibly large corpus
of text. There is ample evidence across the Web of this training material including
copyrighted material, brazenly stolen by the Slop Generator proprietors with
impunity. Due to the nature of Slop Generators, they are prone to regurgitating
their training corpus almost verbatim. This presents a challenge for FOSS projects
in that the use of generated slop is highly likely to violate intellectual property
law by way of regurgitating the aforementioned stolen training material. This
likelihood is proportional to the specificity of the problem area.

Asahi Linux is a _highly_ specific project, working in esoteric problem spaces
on publicly undocumented hardware. Given the techniques used by Slop Generator
manufacturers, it is not impossible for them to have confidential or leaked
material owned by Apple or its vendor partners in their training corpi. It is
therefore likely that Slop Generators will regurgitate this when queried in just
the right way. We already forbid the use of illegally acquired or leaked
documentation and tooling (e.g. Apple's internal repair diagnostic tools). This
also applies to regurgitated slop.

FOSS projects like Asahi Linux cannot afford costly intellectual property lawsuits
in US courts. The current political situation in that nation also makes it
incredibly unlikely that any FOSS project would win such a suit regardless of
the quality of its defence.

## Waste of resources
Slop Generators consume an unfathomable amount of resources we can scarcely afford
to waste. Training, and to a lesser extent inference, require enormous amounts of
energy, water, land, and hardware. Manufacturing the hardware itself requires enormous
amounts of energy, water and minerals. All parts of the Slop Generator supply chain
are environmentally intensive. These resources are better used on quite literally
anything else.

## LMGTFY
An emerging trend we have observed is people copying user questions or posts into
a Slop Generator, then replying to the post with the generated slop. This is
occurring with increasing frequency, particularly on Reddit. For some people it
is tempting to "help" others and answer questions by feeding them to a LLM and
then posting the answer as-is, or lightly edited at best. If this is you, please
realise that others also have access to the same models as you do, and if they
wanted an answer from one, they could have asked it themselves. Doing this is
exactly as helpful as posting a LMGTFY link, and everyone else _will_ view your
actions as if you did exactly that.

## It's just matmul
It is very easy to get caught up in the hype that bad actors have built around
Slop Generators. The anthropomorphic presentation of Slop Generators as "agents"
or "assistants" is a very deliberate attempt to manufacture consent for their
integration into workforces at the expense of human interaction. The implication
of some higher degree intelligence or sentience is very much deliberate, and it
is very much false.

Make no mistake, they cannot think. They cannot reason. They cannot take into
account context. They don't "know" things or have a sense of humour or any of the
other human-centric qualities bad actors would have you believe of them. Slop
Generators are a [chain of matrices in a stochastic system](https://en.wikipedia.org/wiki/Markov_chain).
The output of a Slop Generator is nothing more than a statistical calculation,
where the next word to be generated is decided by an opaque probabilistic
function dependent on previously generated words. This is fundamentally the
same mathematics that is used to predict the weather.

A Slop Generator cannot assess the veracity of its claims, nor can it ever
tell you that it simply does not know something. Slop Generators
are often _confidently incorrect_ as a result, and require brow-beating
to admit a mistake. They are therefore highly inappropriate tools in contexts where
truth and correctness are of utmost importance, and when the user is not already
highly knowledgeable and confident in the problem area. This presents a bit of
an issue for Slop Generators; if the user is already highly knowledgeable and
confident in the problem area, then why ask the Slop Generator in the first place?
